{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":4140,"sourceType":"datasetVersion","datasetId":2477}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport re\nfrom nltk.tokenize import RegexpTokenizer\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import wordnet\nfrom sklearn.metrics import classification_report\nimport torch\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\nimport numpy as np\nimport nltk\nfrom scipy.special import softmax","metadata":{"execution":{"iopub.status.busy":"2024-10-05T19:38:36.561474Z","iopub.execute_input":"2024-10-05T19:38:36.562360Z","iopub.status.idle":"2024-10-05T19:38:40.900264Z","shell.execute_reply.started":"2024-10-05T19:38:36.562318Z","shell.execute_reply":"2024-10-05T19:38:40.899516Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"col_name = ['target','id', 'date','flag', 'user', 'text']\ndataset_encode = \"ISO-8859-1\"\ndf = pd.read_csv('/kaggle/input/sentiment140/training.1600000.processed.noemoticon.csv', encoding = dataset_encode,names=col_name)","metadata":{"execution":{"iopub.status.busy":"2024-10-05T19:38:48.371484Z","iopub.execute_input":"2024-10-05T19:38:48.372057Z","iopub.status.idle":"2024-10-05T19:38:54.000377Z","shell.execute_reply.started":"2024-10-05T19:38:48.372016Z","shell.execute_reply":"2024-10-05T19:38:53.999334Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-05T19:38:54.914308Z","iopub.execute_input":"2024-10-05T19:38:54.914634Z","iopub.status.idle":"2024-10-05T19:38:54.932613Z","shell.execute_reply.started":"2024-10-05T19:38:54.914603Z","shell.execute_reply":"2024-10-05T19:38:54.931687Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   target          id                          date      flag  \\\n0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n\n              user                                               text  \n0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n1    scotthamilton  is upset that he can't update his Facebook by ...  \n2         mattycus  @Kenichan I dived many times for the ball. Man...  \n3          ElleCTF    my whole body feels itchy and like its on fire   \n4           Karoli  @nationwideclass no, it's not behaving at all....  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>id</th>\n      <th>date</th>\n      <th>flag</th>\n      <th>user</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1467810369</td>\n      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>_TheSpecialOne_</td>\n      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1467810672</td>\n      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>scotthamilton</td>\n      <td>is upset that he can't update his Facebook by ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1467810917</td>\n      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>mattycus</td>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1467811184</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>ElleCTF</td>\n      <td>my whole body feels itchy and like its on fire</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1467811193</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>Karoli</td>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df['target'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-10-05T19:39:02.381614Z","iopub.execute_input":"2024-10-05T19:39:02.382496Z","iopub.status.idle":"2024-10-05T19:39:02.409355Z","shell.execute_reply.started":"2024-10-05T19:39:02.382454Z","shell.execute_reply":"2024-10-05T19:39:02.408370Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"target\n0    800000\n4    800000\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df['target']= df['target'].replace(4, 1)\ndf['target'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-10-05T19:39:08.209895Z","iopub.execute_input":"2024-10-05T19:39:08.210788Z","iopub.status.idle":"2024-10-05T19:39:08.247038Z","shell.execute_reply.started":"2024-10-05T19:39:08.210720Z","shell.execute_reply":"2024-10-05T19:39:08.246033Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"target\n0    800000\n1    800000\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"def clean_text(text):\n    \n    stop_words = [\n    \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \n    \"any\", \"are\", \"aren't\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \n    \"below\", \"between\", \"both\", \"but\", \"by\", \"can't\", \"cannot\", \"could\", \"couldn't\", \n    \"did\", \"didn't\", \"do\", \"does\", \"doesn't\", \"doing\", \"don't\", \"down\", \"during\", \n    \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"hadn't\", \"has\", \"hasn't\", \n    \"have\", \"haven't\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \n    \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \n    \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"isn't\", \"it\", \"it's\", \n    \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"mustn't\", \"my\", \"myself\", \"no\", \n    \"nor\", \"not\", \"of\", \"off\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \n    \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"shan't\", \"she\", \"she'd\", \n    \"she'll\", \"she's\", \"should\", \"shouldn't\", \"so\", \"some\", \"such\", \"than\", \"that\", \n    \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \n    \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \n    \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"wasn't\", \n    \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"weren't\", \"what\", \"what's\", \n    \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \n    \"why\", \"why's\", \"with\", \"won't\", \"would\", \"wouldn't\", \"you\", \"you'd\", \"you'll\", \n    \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\"]\n    \n    def get_word_pos(tag):\n        if tag.startswith('V'):\n            return 'v'  # Verb\n        elif tag.startswith('N'):\n            return 'n'  # Noun\n        elif tag.startswith('R'):\n            return 'r'  # Adverb\n        else:\n            return 'n'  # Default to noun\n\n\n\n    \n    #convert to lower\n    text = text.lower()\n    \n    #remove URL\n    text = re.sub(r'(http[s]?://\\S+|www\\.\\S+)', ' ', text)\n    \n    #replace @username with username \n    text = re.sub(r'@[\\S]+', 'User', text)\n    \n    #remove hashtag sign\n    text = re.sub(r'#(\\S)+', r'\\1', text)\n    \n    #remvoe numbers\n    text = re.sub(r'\\d+', '', text )\n    \n    #remove whitespaces\n    text = re.sub(r'\\s+', ' ', text)\n    \n    #strip\n    text = text.strip()\n    \n    #remove stopwords\n    text = ' '.join([word for word in text.split() if word not in stop_words])\n    \n    #tokenize\n    tokenizer = RegexpTokenizer(r'\\w+|[^\\w\\s]')\n    tokens = tokenizer.tokenize(text)\n    \n    #pos\n    pos_tag = nltk.pos_tag(tokens)\n    \n    #lemmatize \n    lemmatizer = WordNetLemmatizer()\n    lammatized_token = [lemmatizer.lemmatize(token, get_word_pos(tag)) for token, tag in pos_tag]\n    \n    return ' '.join(lammatized_token)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-05T19:39:25.543402Z","iopub.execute_input":"2024-10-05T19:39:25.544256Z","iopub.status.idle":"2024-10-05T19:39:25.559744Z","shell.execute_reply.started":"2024-10-05T19:39:25.544214Z","shell.execute_reply":"2024-10-05T19:39:25.558670Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","metadata":{"execution":{"iopub.status.busy":"2024-10-05T19:41:31.473619Z","iopub.execute_input":"2024-10-05T19:41:31.474333Z","iopub.status.idle":"2024-10-05T19:41:31.525306Z","shell.execute_reply.started":"2024-10-05T19:41:31.474290Z","shell.execute_reply":"2024-10-05T19:41:31.524290Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"pos_samples = df[df['target']==1].sample(500, random_state=42)\nneg_samples = df[df['target']==0].sample(500, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-10-05T19:44:22.802094Z","iopub.execute_input":"2024-10-05T19:44:22.802977Z","iopub.status.idle":"2024-10-05T19:44:23.124575Z","shell.execute_reply.started":"2024-10-05T19:44:22.802908Z","shell.execute_reply":"2024-10-05T19:44:23.123534Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"pos_samples.shape, neg_samples.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-05T19:44:40.724674Z","iopub.execute_input":"2024-10-05T19:44:40.725114Z","iopub.status.idle":"2024-10-05T19:44:40.731662Z","shell.execute_reply.started":"2024-10-05T19:44:40.725075Z","shell.execute_reply":"2024-10-05T19:44:40.730650Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"((500, 6), (500, 6))"},"metadata":{}}]},{"cell_type":"code","source":"sub_data = pd.concat([pos_samples, neg_samples])","metadata":{"execution":{"iopub.status.busy":"2024-10-05T19:45:18.678922Z","iopub.execute_input":"2024-10-05T19:45:18.679654Z","iopub.status.idle":"2024-10-05T19:45:18.685227Z","shell.execute_reply.started":"2024-10-05T19:45:18.679611Z","shell.execute_reply":"2024-10-05T19:45:18.684039Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"sub_data.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-05T19:45:28.927002Z","iopub.execute_input":"2024-10-05T19:45:28.927874Z","iopub.status.idle":"2024-10-05T19:45:28.933506Z","shell.execute_reply.started":"2024-10-05T19:45:28.927832Z","shell.execute_reply":"2024-10-05T19:45:28.932559Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"(1000, 6)"},"metadata":{}}]},{"cell_type":"code","source":"sub_data['text'] = sub_data['text'].apply(clean_text)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-05T19:45:50.530051Z","iopub.execute_input":"2024-10-05T19:45:50.530837Z","iopub.status.idle":"2024-10-05T19:45:51.440831Z","shell.execute_reply.started":"2024-10-05T19:45:50.530792Z","shell.execute_reply":"2024-10-05T19:45:51.440039Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"\ntokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n\n\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-10-05T19:53:23.558610Z","iopub.execute_input":"2024-10-05T19:53:23.559479Z","iopub.status.idle":"2024-10-05T19:53:27.910551Z","shell.execute_reply.started":"2024-10-05T19:53:23.559435Z","shell.execute_reply":"2024-10-05T19:53:27.909659Z"},"trusted":true},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/929 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de688f4308db4338b44a5b2e897455d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f39e2236fb7c4dccaf5def20cf019a06"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6f039e023eb4f0dafb3a9f8e366e708"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3b6e6921e154774a569928de3666248"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/501M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"477c08275aff40c582ba48a0283deb09"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"RobertaForSequenceClassification(\n  (roberta): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n      (position_embeddings): Embedding(514, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (classifier): RobertaClassificationHead(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"def predict_sentiment(text):\n    encoded_input = tokenizer(text, return_tensors='pt').to(device)\n    with torch.no_grad():\n        output = model(**encoded_input)\n    scores = output[0][0].cpu().numpy()\n    scores = softmax(scores)\n\n    negative_score = scores[0]\n    positive_score = scores[2]\n    return 1 if positive_score > negative_score else 0","metadata":{"execution":{"iopub.status.busy":"2024-10-05T19:53:30.574424Z","iopub.execute_input":"2024-10-05T19:53:30.575183Z","iopub.status.idle":"2024-10-05T19:53:30.580763Z","shell.execute_reply.started":"2024-10-05T19:53:30.575139Z","shell.execute_reply":"2024-10-05T19:53:30.579775Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"sub_data['sentiment'] = sub_data['text'].apply(predict_sentiment)","metadata":{"execution":{"iopub.status.busy":"2024-10-05T19:53:31.586347Z","iopub.execute_input":"2024-10-05T19:53:31.586735Z","iopub.status.idle":"2024-10-05T19:53:40.458468Z","shell.execute_reply.started":"2024-10-05T19:53:31.586687Z","shell.execute_reply":"2024-10-05T19:53:40.457394Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"sub_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-05T19:53:40.460520Z","iopub.execute_input":"2024-10-05T19:53:40.461209Z","iopub.status.idle":"2024-10-05T19:53:40.473471Z","shell.execute_reply.started":"2024-10-05T19:53:40.461158Z","shell.execute_reply":"2024-10-05T19:53:40.472624Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"         target          id                          date      flag  \\\n1012188       1  1881179620  Fri May 22 03:51:54 PDT 2009  NO_QUERY   \n1099036       1  1970537555  Sat May 30 04:15:49 PDT 2009  NO_QUERY   \n1275978       1  2001154935  Tue Jun 02 00:00:21 PDT 2009  NO_QUERY   \n1388988       1  2053074174  Sat Jun 06 03:10:08 PDT 2009  NO_QUERY   \n938859        1  1793548492  Thu May 14 03:06:55 PDT 2009  NO_QUERY   \n\n                   user                                               text  \\\n1012188        tarawade  lookin ward long weekend really dont want go w...   \n1099036  Millie_stillie                      s music live meet people make   \n1275978         zsangel                           figure internet new ipod   \n1388988     krisignacio   User wait worship guy tonight . it ' ll much fun   \n938859          _DrInE_  User congrats james ! ! sure book go huge success   \n\n         sentiment  \n1012188          0  \n1099036          1  \n1275978          1  \n1388988          1  \n938859           1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>id</th>\n      <th>date</th>\n      <th>flag</th>\n      <th>user</th>\n      <th>text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1012188</th>\n      <td>1</td>\n      <td>1881179620</td>\n      <td>Fri May 22 03:51:54 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>tarawade</td>\n      <td>lookin ward long weekend really dont want go w...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1099036</th>\n      <td>1</td>\n      <td>1970537555</td>\n      <td>Sat May 30 04:15:49 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>Millie_stillie</td>\n      <td>s music live meet people make</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1275978</th>\n      <td>1</td>\n      <td>2001154935</td>\n      <td>Tue Jun 02 00:00:21 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>zsangel</td>\n      <td>figure internet new ipod</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1388988</th>\n      <td>1</td>\n      <td>2053074174</td>\n      <td>Sat Jun 06 03:10:08 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>krisignacio</td>\n      <td>User wait worship guy tonight . it ' ll much fun</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>938859</th>\n      <td>1</td>\n      <td>1793548492</td>\n      <td>Thu May 14 03:06:55 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>_DrInE_</td>\n      <td>User congrats james ! ! sure book go huge success</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"y_true = sub_data['target']\ny_pred = sub_data['sentiment']\nreport = classification_report(y_true, y_pred, target_names=[\"negative\", \"positive\"])\nprint(report)","metadata":{"execution":{"iopub.status.busy":"2024-10-05T19:53:40.474553Z","iopub.execute_input":"2024-10-05T19:53:40.474842Z","iopub.status.idle":"2024-10-05T19:53:40.490564Z","shell.execute_reply.started":"2024-10-05T19:53:40.474799Z","shell.execute_reply":"2024-10-05T19:53:40.489769Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n    negative       0.77      0.61      0.68       500\n    positive       0.68      0.82      0.74       500\n\n    accuracy                           0.71      1000\n   macro avg       0.72      0.71      0.71      1000\nweighted avg       0.72      0.71      0.71      1000\n\n","output_type":"stream"}]},{"cell_type":"code","source":"def test_single_tweet(tweet):\n    tweet = clean_text(tweet)\n    sentiment = predict_sentiment(tweet)\n\n   \n    return \"positive\" if sentiment == 1 else \"negative\"","metadata":{"execution":{"iopub.status.busy":"2024-10-05T19:54:32.169210Z","iopub.execute_input":"2024-10-05T19:54:32.169954Z","iopub.status.idle":"2024-10-05T19:54:32.175593Z","shell.execute_reply.started":"2024-10-05T19:54:32.169913Z","shell.execute_reply":"2024-10-05T19:54:32.174741Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"test_tweet = \"I #hatedata science brain #dsbrain\"\npredicted_sentiment = test_single_tweet(test_tweet)\nprint(f\"The sentiment of the tweet '{test_tweet}' is {predicted_sentiment}.\")","metadata":{"execution":{"iopub.status.busy":"2024-10-05T19:54:42.526650Z","iopub.execute_input":"2024-10-05T19:54:42.527556Z","iopub.status.idle":"2024-10-05T19:54:42.543881Z","shell.execute_reply.started":"2024-10-05T19:54:42.527515Z","shell.execute_reply":"2024-10-05T19:54:42.543038Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"The sentiment of the tweet 'I #hatedata science brain #dsbrain' is positive.\n","output_type":"stream"}]}]}